# -*- coding: utf-8 -*-
"""Copy of CSE_151B_PA3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-GGaX9Zo-bPCbWwGPQ32OGylgHnEFc1x
"""

import csv
import random
from shutil import copyfile
from pycocotools.coco import COCO
from tqdm import tqdm

# Loading Annotations
!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip
# Loading Images
!wget http://images.cocodataset.org/zips/train2014.zip
!wget http://images.cocodataset.org/zips/val2014.zip
!unzip /annotations_trainval2014.zip
!unzip train2014.zip
!unzip val2014.zip
#make directory and get annotations for training and testing
!mkdir data
!mkdir data/annotations
!cp -fR /annotations /data
!mkdir data/images
!mkdir data/images/train
!mkdir data/images/val
!mkdir data/images/test

coco = COCO('./data/annotations/captions_train2014.json')
#get ids of training images
with open('train_ids.csv', 'r') as f:
    reader = csv.reader(f)
    trainIds = list(reader)
    
trainIds = [int(i) for i in trainIds[0]]

with open('val_ids.csv', 'r') as f:
    reader = csv.reader(f)
    valIds = list(reader)
    
valIds = [int(i) for i in valIds[0]]

for img_id in trainIds:
    path = coco.loadImgs(img_id)[0]['file_name']
    copyfile('/train2014/'+path, './data/images/train/'+path)
for img_id in valIds:
    path = coco.loadImgs(img_id)[0]['file_name']
    copyfile('/train2014/'+path, './data/images/val/'+path)

cocoTest = COCO('./data/annotations/captions_val2014.json')

with open('test_ids.csv', 'r') as f:
    reader = csv.reader(f)
    testIds = list(reader)
    
testIds = [int(i) for i in testIds[0]]

for img_id in testIds:
    path = cocoTest.loadImgs(img_id)[0]['file_name']
    copyfile('/val2014/'+path, './data/images/test/'+path)

from file_utils import *
from dataset_factory import *
name = 'task-1-default-config'
config_data = read_file_in_dir('./', name + '.json')
coco, coco_test, vocab, train_loader, val_loader, test_loader = get_datasets(config_data)

def validation(encoder,decoder):
    encoder.eval()
    decoder.eval()
    total_loss = 0.0
    for i, (images , annotations , ids) in enumerate(val_loader):
        images = images.to(device)
        annotations = annotations.to(device)

        ## forward + loss
        images = encoder(images)
        logits = decoder(images,annotations,teacher_forcing=True)
        one_hot_annotation = torch.nn.functional.one_hot(annotations, num_classes=14463).type(torch.float)
        loss = criterion(logits[:,:-1,:], one_hot_annotation)
        
        total_loss += loss.detach().item()
    total_loss = total_loss / i
    return total_loss

import tqdm
import random
import matplotlib.pyplot as plt
import numpy as np
import torch
from datetime import datetime
import math
import tqdm
from copy import deepcopy
from nltk.tokenize import word_tokenize
import caption_utils
from torch.optim import lr_scheduler

from dataset_factory import *
from file_utils import *
from model_factory import *

def train(encoder, decoder, optimizer, criterion):

    num_epochs = config_data['experiment']['num_epochs']
    current_epoch = 0
    training_losses = [1e10]*num_epochs
    val_losses = [1e10]*num_epochs
    min_loss = 1e10
    early_stop = config_data['experiment']['early_stop']
    patience = config_data['experiment']['patience']
    batch_size = config_data['dataset']['batch_size']
    patience_count = 0

    # Decay LR by a factor of 0.1 every 3 epochs
    my_lr_scheduler = lr_scheduler.StepLR(optimizer,step_size=3,gamma=0.1)

    for epoch in tqdm.trange(num_epochs):
        train_running_loss = 0.0
        train_acc = 0.0

        ## training step
        encoder.train()
        decoder.train()
        for i, (images , annotations , ids) in enumerate(train_loader):


            device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
            images = images.to(device)
            annotations = annotations.to(device)

            ## forward + backprop + loss
            images = encoder(images)
            logits = decoder(images,annotations,teacher_forcing=True)
            one_hot_annotation = torch.nn.functional.one_hot(annotations, num_classes=14463).type(torch.float)
            loss = criterion(logits[:,:-1,:], one_hot_annotation)
            
            optimizer.zero_grad()
            loss.backward()

            ## update model params
            optimizer.step()

            train_running_loss += loss.detach().item()

        val_loss = validation(encoder,decoder)
        # save best model
        if val_loss < min_loss:
            min_loss = val_loss
            best_encoder = deepcopy(encoder)
            best_decoder = deepcopy(decoder)

        train_loss = train_running_loss / i
        print('Epoch: %d | Loss: %.4f | Loss: %.4f' %(epoch, train_loss, val_loss))
        val_losses[epoch] = val_loss
        training_losses[epoch] = train_running_loss / i
        if my_lr_scheduler is not None:
            my_lr_scheduler.step()

        # early stop if model starts overfitting
        if early_stop:
            if epoch > 0 and val_loss > val_losses[epoch - 1]:
                patience_count += 1
            if patience_count >= patience:
                print('\nEarly stopping!')
                break

    return best_encoder, best_decoder, training_losses ,val_losses

"""Training CNN LSTM"""

from model_factory import *
learning_rate = config_data['experiment']['learning_rate']
embedding_size = config_data['model']['embedding_size']

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
CNN_encoder = CustomCNN(outputs = embedding_size).to(device)
CNN_decoder = CNN_LSTM(config_data,vocab).to(device)

criterion = nn.CrossEntropyLoss().to(device)
optimizer = torch.optim.Adam(list(CNN_encoder.parameters())+list(CNN_decoder.parameters()), lr=learning_rate)

best_CNN_encoder, best_CNN_decoder, CNN_training_losses ,CNN_val_losses = train(CNN_encoder,CNN_decoder,optimizer,criterion)

plt.plot(CNN_training_losses[0:8],label="training_losses")
plt.plot(CNN_val_losses[0:8],label="val_loss")
plt.legend()

"""Training ResNet LSTM"""

from torch.optim import lr_scheduler
import torchvision
num_classes = config_data['model']['embedding_size']
learning_rate = config_data['experiment']['learning_rate']

model_res = torchvision.models.resnet50(weights="IMAGENET1K_V2")
# set requires_grad = False to freeze the parameters so that the gradients are not computed in backward()
for param in model_res.parameters():
    param.requires_grad = False
# Parameters of newly constructed modules have requires_grad=True by default
model_res.fc = nn.Linear(model_res.fc.in_features, num_classes)

# Possible passing task to GPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_res = model_res.to(device)
res_decoder = CNN_LSTM(config_data,vocab).to(device)

criterion = nn.CrossEntropyLoss()

# Only fully connected layers are optimized using the original way, paving the way of using linear
# layer to a trainable linear layer to map from the penultimate hidden layer dimension to the hidden LSTM dimension.
optimizer_res = torch.optim.Adam(list(model_res.fc.parameters())+list(res_decoder.parameters()), lr=learning_rate)

best_ResNet_encoder, best_ResNet_decoder, ResNet_training_losses ,ResNet_val_losses = train(model_res,res_decoder,optimizer_res,criterion)

plt.plot(ResNet_training_losses[0:7],label="training_losses")
plt.plot(ResNet_val_losses[0:7],label="val_loss")
plt.legend()

from caption_utils import *
from nltk.tokenize import word_tokenize
def generate(model,images,annotations,img_id,configs=None,testing=False):
    temperature = config_data['generation']['temperature']
    deterministic =  config_data['generation']['deterministic']
    max_length = config_data['generation']['max_length']
    smx = nn.Softmax(dim=2)

    bleu1_list = []
    bleu4_list = []

    if testing:
        co = coco_test
    else:
        co = coco

    h_0 = torch.zeros(model.num_layers,images.size(0),model.hidden_size).to(device)
    c_0 = torch.zeros(model.num_layers,images.size(0),model.hidden_size).to(device)

    def hidden2vocab_id(hidden,deterministic=False,temperature=0.4):
        smx = nn.Softmax(dim=2)
        if deterministic:
            vocab_id = torch.argmax(smx(hidden),dim=2)
        else:
            vocab_id = torch.multinomial(smx(hidden/temperature).view(-1,14463),1)
            seq_len = hidden.size(1)
            # vocab_id = vocab_id.view(-1,seq_len,1)
            vocab_id = vocab_id.view(-1,seq_len)
        return vocab_id
    
    prediction , _ = model.lstm(images.view(-1,1,model.embedding_size),(h_0,c_0))
    prediction = model.fc(prediction)
    prediction = hidden2vocab_id(prediction,deterministic,temperature)
    for i in range(max_length-1):
        prediction = model(images, prediction, teacher_forcing=True)
        # prediction = model.embedding(prediction)
        # input = torch.cat((images.view(-1,1,model.embedding_size),prediction),dim=1)
        # prediction , _ = model.lstm(input,(h_0,c_0))
        # prediction = model.fc(prediction)
        prediction = hidden2vocab_id(prediction,deterministic,temperature)

    for k in range(images.size(0)):
        predicted_caption = list(map(vocab.idx2word.get,prediction[k].tolist()))
        try:
            predicted_caption = predicted_caption[predicted_caption.index('<start>')+1:predicted_caption.index('<end>')]
        except:
            try:
                predicted_caption = predicted_caption[predicted_caption.index('<start>')+1:predicted_caption.index('<pad>')]
            except:
                pass
        print("Pridiction:"," ".join(predicted_caption))

        # reference_captions = list(map(vocab.idx2word.get,annotations[k].tolist()))
        # reference_captions =reference_captions[reference_captions.index('<start>')+1:reference_captions.index('<end>')]
        reference_captions = [co.anns[i]['caption'].lower() for i in co.getAnnIds(img_id[k])]
        print("Reference:")
        for text in reference_captions:
            print(text)
        

        reference_captions = [word_tokenize(reference_captions[j]) for j in range(len(reference_captions))]
        bleu1_score = bleu1(reference_captions,predicted_caption)
        bleu4_score = bleu4(reference_captions,predicted_caption)
        bleu1_list.append(bleu1_score)
        bleu4_list.append(bleu4_score)
        print("bleu1 score: ",bleu1_score)
        print("bleu4 score: ",bleu4_score)
    return bleu1_list, bleu4_list

stopper = 5
total_CNN_bleu1 = []
total_CNN_bleu4 = []

for i , (im, an, id) in enumerate(test_loader):
    im = im.cuda()
    an = an.cuda()
    CNN_bleu1 , CNN_bleu4 = generate(best_CNN_decoder,best_CNN_encoder(im),an,id,testing=True)
    total_CNN_bleu1 = total_CNN_bleu1 + CNN_bleu1
    total_CNN_bleu4 = total_CNN_bleu4 + CNN_bleu4
    if i == 5:
        break

plt.hist(total_CNN_bleu1)
plt.title("CNN->LSTM Bleu1")
plt.figure()
plt.hist(total_CNN_bleu4)
plt.title("CNN->LSTM Bleu4")

stopper = 5
total_ResNet_bleu1 = []
total_ResNet_bleu4 = []

for i , (im, an, id) in enumerate(test_loader):
    im = im.cuda()
    an = an.cuda()
    ResNet_bleu1 , ResNet_bleu4 = generate(best_ResNet_decoder,best_ResNet_encoder(im),an,id,testing=True)
    total_ResNet_bleu1 = total_ResNet_bleu1 + ResNet_bleu1
    total_ResNet_bleu4 = total_ResNet_bleu4 + ResNet_bleu4
    if i == 5:
        break

plt.hist(ResNet_bleu1)
plt.title("ResNet->LSTM Bleu1")
plt.figure()
plt.title("ResNet->LSTM Bleu4")
plt.hist(ResNet_bleu4)

name = 'task-1-1024hidden-config'
config_data = read_file_in_dir('./', name + '.json')

from model_factory import *
learning_rate = config_data['experiment']['learning_rate']
embedding_size = config_data['model']['embedding_size']

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
CNN_encoder = CustomCNN(outputs = embedding_size).to(device)
CNN_decoder = CNN_LSTM(config_data,vocab).to(device)

criterion = nn.CrossEntropyLoss().to(device)
optimizer = torch.optim.Adam(list(CNN_encoder.parameters())+list(CNN_decoder.parameters()), lr=learning_rate)

para_1_best_CNN_encoder, para_1_best_CNN_decoder, para_1_CNN_training_losses ,para_1_CNN_val_losses = train(CNN_encoder,CNN_decoder,optimizer,criterion)

plt.plot(para_1_CNN_training_losses[0:8],label="training_losses")
plt.plot(para_1_CNN_val_losses[0:8],label="val_loss")
plt.title("Train & Val Loss on CNN->LSTM with 1024 LSTM hidden output")
plt.legend()

from torch.optim import lr_scheduler
import torchvision
num_classes = config_data['model']['embedding_size']
learning_rate = config_data['experiment']['learning_rate']

model_res = torchvision.models.resnet50(weights="IMAGENET1K_V2")
# set requires_grad = False to freeze the parameters so that the gradients are not computed in backward()
for param in model_res.parameters():
    param.requires_grad = False
# Parameters of newly constructed modules have requires_grad=True by default
model_res.fc = nn.Linear(model_res.fc.in_features, num_classes)

# Possible passing task to GPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_res = model_res.to(device)
res_decoder = CNN_LSTM(config_data,vocab).to(device)

criterion = nn.CrossEntropyLoss()

# Only fully connected layers are optimized using the original way, paving the way of using linear
# layer to a trainable linear layer to map from the penultimate hidden layer dimension to the hidden LSTM dimension.
optimizer_res = torch.optim.Adam(list(model_res.fc.parameters())+list(res_decoder.parameters()), lr=learning_rate)

para_1_best_ResNet_encoder, para_1_best_ResNet_decoder, para_1_ResNet_training_losses ,para_1_ResNet_val_losses = train(model_res,res_decoder,optimizer_res,criterion)

plt.plot(para_1_ResNet_training_losses[0:7],label="training_losses")
plt.plot(para_1_ResNet_val_losses[0:7],label="val_loss")
plt.title("Train & Val Loss on ResNet->LSTM with 1024 LSTM hidden output")
plt.legend()

stopper = 5
para_1_total_CNN_bleu1 = []
para_1_total_CNN_bleu4 = []

for i , (im, an, id) in enumerate(test_loader):
    im = im.cuda()
    an = an.cuda()
    CNN_bleu1 , CNN_bleu4 = generate(para_1_best_CNN_decoder,para_1_best_CNN_encoder(im),an,id,testing=True)
    para_1_total_CNN_bleu1 = para_1_total_CNN_bleu1 + CNN_bleu1
    para_1_total_CNN_bleu4 = para_1_total_CNN_bleu4 + CNN_bleu4
    if i == 5:
        break

plt.hist(para_1_total_CNN_bleu1)
plt.title("CNN->LSTM Bleu1")
plt.figure()
plt.hist(para_1_total_CNN_bleu4)
plt.title("CNN->LSTM Bleu4")

stopper = 5
para_1_total_ResNet_bleu1 = []
para_1_total_ResNet_bleu4 = []

for i , (im, an, id) in enumerate(test_loader):
    im = im.cuda()
    an = an.cuda()
    ResNet_bleu1 , ResNet_bleu4 = generate(para_1_best_ResNet_decoder,para_1_best_ResNet_encoder(im),an,id,testing=True)
    para_1_total_ResNet_bleu1 = para_1_total_ResNet_bleu1 + ResNet_bleu1
    para_1_total_ResNet_bleu4 = para_1_total_ResNet_bleu4 + ResNet_bleu4
    if i == 5:
        break

plt.hist(para_1_total_ResNet_bleu1)
plt.title("ResNet->LSTM Bleu1")
plt.figure()
plt.title("ResNet->LSTM Bleu4")
plt.hist(para_1_total_ResNet_bleu4)

name = 'task-1-600emsize-config'
config_data = read_file_in_dir('./', name + '.json')

from model_factory import *
learning_rate = config_data['experiment']['learning_rate']
embedding_size = config_data['model']['embedding_size']

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
CNN_encoder = CustomCNN(outputs = embedding_size).to(device)
CNN_decoder = CNN_LSTM(config_data,vocab).to(device)

criterion = nn.CrossEntropyLoss().to(device)
optimizer = torch.optim.Adam(list(CNN_encoder.parameters())+list(CNN_decoder.parameters()), lr=learning_rate)

para_2_best_CNN_encoder, para_2_best_CNN_decoder, para_2_CNN_training_losses ,para_2_CNN_val_losses = train(CNN_encoder,CNN_decoder,optimizer,criterion)

plt.plot(para_2_CNN_training_losses[0:7],label="training_losses")
plt.plot(para_2_CNN_val_losses[0:7],label="val_loss")
plt.title("Train & Val Loss on CNN->LSTM with 600 CNN output")
plt.legend()

stopper = 5
para_2_total_CNN_bleu1 = []
para_2_total_CNN_bleu4 = []

for i , (im, an, id) in enumerate(test_loader):
    im = im.cuda()
    an = an.cuda()
    CNN_bleu1 , CNN_bleu4 = generate(para_2_best_CNN_decoder,para_2_best_CNN_encoder(im),an,id,testing=True)
    para_2_total_CNN_bleu1 = para_2_total_CNN_bleu1 + CNN_bleu1
    para_2_total_CNN_bleu4 = para_2_total_CNN_bleu4 + CNN_bleu4
    if i == 5:
        break

plt.hist(para_2_total_CNN_bleu1)
plt.title("CNN->LSTM Bleu1")
plt.figure()
plt.hist(para_2_total_CNN_bleu4)
plt.title("CNN->LSTM Bleu4")

from torch.optim import lr_scheduler
import torchvision
num_classes = config_data['model']['embedding_size']
learning_rate = config_data['experiment']['learning_rate']

model_res = torchvision.models.resnet50(weights="IMAGENET1K_V2")
# set requires_grad = False to freeze the parameters so that the gradients are not computed in backward()
for param in model_res.parameters():
    param.requires_grad = False
# Parameters of newly constructed modules have requires_grad=True by default
model_res.fc = nn.Linear(model_res.fc.in_features, num_classes)

# Possible passing task to GPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_res = model_res.to(device)
res_decoder = CNN_LSTM(config_data,vocab).to(device)

criterion = nn.CrossEntropyLoss()

# Only fully connected layers are optimized using the original way, paving the way of using linear
# layer to a trainable linear layer to map from the penultimate hidden layer dimension to the hidden LSTM dimension.
optimizer_res = torch.optim.Adam(list(model_res.fc.parameters())+list(res_decoder.parameters()), lr=learning_rate)

para_2_best_ResNet_encoder, para_2_best_ResNet_decoder, para_2_ResNet_training_losses ,para_2_ResNet_val_losses = train(model_res,res_decoder,optimizer_res,criterion)

plt.plot(para_2_ResNet_training_losses[0:7],label="training_losses")
plt.plot(para_2_ResNet_val_losses[0:7],label="val_loss")
plt.title("Train & Val Loss on ResNet->LSTM with 1024 LSTM hidden output")
plt.legend()

stopper = 5
para_2_total_ResNet_bleu1 = []
para_2_total_ResNet_bleu4 = []

for i , (im, an, id) in enumerate(test_loader):
    im = im.cuda()
    an = an.cuda()
    ResNet_bleu1 , ResNet_bleu4 = generate(para_2_best_ResNet_decoder,para_2_best_ResNet_encoder(im),an,id,testing=True)
    para_2_total_ResNet_bleu1 = para_2_total_ResNet_bleu1 + ResNet_bleu1
    para_2_total_ResNet_bleu4 = para_2_total_ResNet_bleu4 + ResNet_bleu4
    if i == 5:
        break

plt.hist(para_2_total_ResNet_bleu1)
plt.title("ResNet->LSTM Bleu1")
plt.figure()
plt.title("ResNet->LSTM Bleu4")
plt.hist(para_2_total_ResNet_bleu4)